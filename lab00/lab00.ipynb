{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-thong",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab00.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `datascience` to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome! This notebook is an unofficial resource that serves as an introduction to working with Python's widely used Pandas library for students who have taken Introduction to Data Science. The functions introduced will be analogous to those in Berkeley's `datascience` module, with examples provided for each.\n",
    "\n",
    "We will cover the following topics in this notebook:\n",
    "1. [Basics of Pandas](#basics)\n",
    "    - [Importing and Loading Packages](#import)\n",
    "<br>\n",
    "<br>\n",
    "2. [Dataframes: Working with Tabular Data](#dataframes)\n",
    "    - [Creating a Dataframe](#creating)\n",
    "    - [Accessing Values in Dataframe](#accessing)\n",
    "    - [Manipulating Data](#manipulating)\n",
    "<br>\n",
    "<br>\n",
    "3. [Visualizing Data](#visualizing)\n",
    "    - [Histograms](#histograms)\n",
    "    - [Line Plots](#line)\n",
    "    - [Scatter Plots](#scatter)\n",
    "    - [Bar Plots](#bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basics <a id='basics'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes familiarity with Python concepts, syntax and data structures at the level of Data 8. For a brief refresher on some Python concepts, refer to this [Python Basics Guide on Github](https://github.com/TiesdeKok/LearnPythonforResearch/blob/master/0_python_basics.ipynb)\n",
    "\n",
    "Python has a great ecosystem of data-centric packages which makes it excellent for data analysis. Pandas is one of those packages, and makes importing and analyzing data much easier. Pandas builds on packages like NumPy and matplotlib to give us a single, convenient, place to do most of our data analysis and visualization work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing and Loading Packages <a id='import'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the `datascience` and `numpy` packages the `import` keyword. Since we Pandas as `pd`, we need to prefix all functions with `pd`, similar to how we prefix all numpy functions with `np` (e.g. as `np.append()`).\n",
    "\n",
    "Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the datascience package, the numpy package, and the pandas library as pd\n",
    "from datascience import * \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataframes: Working with Tabular Data <a id='dataframes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python's `datascience` module, we used `Table` to build our dataframes and used commands such as `select()`, `where()`, `group()`, `column()` etc. In this section, we will go over some basic commands to work with tabular data in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating a Dataframe <a id='creating'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas introduces a data structure (i.e. dataframe) that represents data as a table with columns and rows. \n",
    "\n",
    "In Python's `datascience` module that is used in Introduction to Data Science, this is how we created tables from scratch by extending an empty table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Table().with_columns([\n",
    "     'letter', ['a', 'b', 'c', 'z'],\n",
    "     'count',  [  9,   3,   3,   1],\n",
    "     'points', [  1,   2,   2,  10],\n",
    " ])\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can use the function `pd.DataFrame` to initialize a dataframe from a dictionary or a list-like object. Refer to the [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from a dictionary\n",
    "df_from_dict = pd.DataFrame({'letter' : ['a', 'b', 'c', 'z'],\n",
    "                             'count'  : [  9,   3,   3,   1],\n",
    "                             'points' : [  1,   2,   2,  10]\n",
    "                            })\n",
    "df_from_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More often, we will need to create a dataframe by importing data from a .csv file. In `datascience`, this is how we read data from a csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datascience_baby = Table.read_table('baby.csv')\n",
    "datascience_baby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use `pd.read.csv()` to read data from a csv file. Sometimes, depending on the data file, we may need to specify the parameters `sep`, `header` or `encoding` as well. For a full list of parameters, refer to [this guide](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).\n",
    "\n",
    "**Note:** The `.head()` method will display the rows of a data frame object.\n",
    "\n",
    "**Reminder:** A Python **function** is a sequence of statements, given a name, that execute in a specific order. In Introduction to Data Science, we talked about built-in and user-defined functions. A Python **method** is like a function, except it is attached to an object. We call a method on an object, and it may or may not make changes to that object. A method, then, belongs to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby = pd.read_csv('baby.csv')\n",
    "baby.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.1.1.** Create a dataframe named `baby_smoker` that contains only the observations where `Maternal Smoker` is True.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1_1\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_smoker = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-pricing",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.1.2.** Create a dataframe named `baby_over40` that contains only the observations where `Maternal Age` is at least 40.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1_2\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_over40 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(baby_over40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.describe` method generates a set of summary statistics of the Series or Dataframe provided.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view summary of data\n",
    "baby.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "sat = pd.read_csv('sat2014.csv', index_col = 0)\n",
    "sat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view information about dataframe\n",
    "# view dimensions (rows, cols)\n",
    "print(sat.shape)\n",
    "\n",
    "# view column names\n",
    "print(sat.columns.values) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.1.3.** Rename the `Combined` column to `Total Score`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1_3\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-elizabeth",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.1.4.** Create a dataframe named `sat_part5` that only contains states where the `Participation Rate` is more than 80.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1_4\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_part5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-president",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Accessing Values in Dataframe <a id='accessing'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `datascience`, we can use `.column()` to access values in a particular column as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access column 'letter' and return an array\n",
    "t.column('letter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, columns are also known as Series. We can access a Pandas series by using the square bracket notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# returns series object\n",
    "sat['State']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want a numpy array of column values, we can call the method `.values` on a Series object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat['State'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `datascience`, we can use `.take()` to access a row in the Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first two rows using python's slicing notation\n",
    "t.take[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can access rows and column by their position using the `iloc` method. We need to specify the rows and columns we want in the following syntax: `df.iloc[<rows>, <columns>]`. For more information on indexing, refer to [this guide](https://pandas.pydata.org/pandas-docs/stable/indexing.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.2.1.** Select the first two rows of the `baby` dataframe using `iloc`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_2_1\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-edmonton",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify row indices\n",
    "baby.iloc[[1, 4, 6], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.2.2.** Select the value in the tenth row and fourth column of the `baby` dataframe by passing in the row and column indices.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_2_1\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-general",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Manipulating Data <a id='manipulating'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. Adding Columns\n",
    "\n",
    "Adding a new column in `datascience` is done by the `.with_column()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.with_column('vowel', ['yes', 'no', 'no', 'no'])\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can use the bracket notation and assign a list to add to the dataframe as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add a new column\n",
    "df_from_dict['newcol'] = [5, 6, 7, 8]\n",
    "df_from_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add an existing column to the new dataframe as a new column by performing an operation on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add count * 2 to the dataframe\n",
    "df_from_dict['doublecount'] = df_from_dict['count'] * 2\n",
    "df_from_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. Selecting Columns\n",
    "\n",
    "In `datascience`, we used `.select()` to subset the dataframe by selecting columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.select(['letter', 'points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use a double bracket notation to select columns. This returns a dataframe, unlike a Series object when we only use single bracket notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double bracket notation for new dataframe\n",
    "df_from_dict[['count', 'doublecount']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3. Filtering Rows Conditionally\n",
    "\n",
    "In `datascience`, we used `.where()` to select rows according to a given condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows where points == 2\n",
    "t.where('points', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows where count < 8\n",
    "t.where(t['count'] < 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can use the bracket notation to subset the dataframe based on a condition. We first specify a condition and then subset using the bracket notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# array of booleans\n",
    "baby['Maternal Smoker'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filter rows by condition Maternal.Smoker == True\n",
    "baby[baby['Maternal Smoker'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter with multiple conditions\n",
    "df_from_dict[(df_from_dict['count'] < 8) & (df_from_dict['points'] > 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4. Renaming Columns\n",
    "\n",
    "In `datascience`, we used `.relabeled()` to rename columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 'points' to 'other name'\n",
    "t.relabeled('points', 'other name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas uses `rename()`, which has an `index` parameter that needs to be set to `str` and a `columns` parameter that needs to be set to a dictionary of the names to be replaced with their replacements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 'points' to 'other name'\n",
    "df_from_dict.rename(index = str, columns = {\"points\" : \"other name\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5. Sorting Dataframe by Column\n",
    "\n",
    "In `datascience` we used `.sort()` to sort a Table according to the values in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by count\n",
    "t.sort('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use the `sort_values()` to sort by column. We need the `by` parameter to specify the row we want to sort by and the optional parameter `ascending = False` if we want to sort in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by count, descending\n",
    "df_from_dict.sort_values(by = ['count'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.6. Grouping and Aggregating\n",
    "\n",
    "In `datascience`, we used `group()` and the `collect` argument to group a Table by a column and aggregrate values in another column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by count and aggregate by sum\n",
    "t.select(['count', 'points']).group('count', collect = sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use `groupby()` to group the dataframe. This function returns a groupby object, on which we can then call an aggregation function to return a dataframe with aggregated values for other columns. For more information, refer to the [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select two columns\n",
    "df_subset = df_from_dict[['count', 'points']]\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_sums_df = df_subset.groupby(['count']).sum()\n",
    "count_sums_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Pivot Tables\n",
    "\n",
    "In `datascience`, we used the `pivot()` function to build contingency tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cones_tbl = Table().with_columns(\n",
    "    'Flavor', make_array('strawberry', 'chocolate', 'chocolate', 'strawberry', 'chocolate', 'bubblegum'),\n",
    "    'Color', make_array('pink', 'light brown', 'dark brown', 'pink', 'dark brown', 'pink'),\n",
    "    'Price', make_array(3.55, 4.75, 5.25, 5.25, 5.25, 4.75)\n",
    ")\n",
    "\n",
    "cones_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pivot on color and flavor\n",
    "cones_tbl.pivot(\"Flavor\", \"Color\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass in the parameters `values` to specify the values in the table and `collect` to specify the aggregration function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameter values and collect\n",
    "cones_tbl.pivot(\"Flavor\", \"Color\", values = \"Price\", collect = np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use `pd.pivot_table()` to create a contingency table. The argument `columns` is similar to the first argument in `datascience`'s `pivot` function and sets the column names of the pivot table. The argument `index` is similar to the second argument in `datascience`'s `pivot` function and sets the first column of the pivot table or the keys to group on. For more information, refer to the [documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe\n",
    "cones_df = pd.DataFrame({\"Flavor\" : ['strawberry', 'chocolate', 'chocolate', 'strawberry', 'chocolate', 'bubblegum'],\n",
    "                         \"Color\"  : ['pink', 'light brown', 'dark brown', 'pink', 'dark brown', 'pink'],\n",
    "                         \"Price\"  : [3.55, 4.75, 5.25, 5.25, 5.25, 4.75]})\n",
    "cones_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pivot table\n",
    "pd.pivot_table(cones_df, columns = [\"Flavor\"], index = [\"Color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is no data in the groups, then Pandas will output `NaN` values. `NaN`, standing for not a number, is a numeric data type used to represent any value that is undefined or unpresentable. `NaN` is also assigned to variables, in a computation, that do not have values and have yet to be computed. `NaN` is specifically a floating-point value; there is no equivalent NaN value for integers, strings, or other types.\n",
    "\n",
    "We can also specify the parameters like `values` (equivalent to `values` in `datascience`'s `pivot`) and `aggfunc` (equivalent to `collect` in `datascience`'s `pivot`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# additional arguments\n",
    "pd.pivot_table(cones_df, columns = [\"Flavor\"], index = [\"Color\"], values = \"Price\", aggfunc = np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1. Joining and Merging\n",
    "\n",
    "In `datascience`, we used `join()` to join two tables based on shared values in columns. We specify the column name in the first table to match on, the name of the second table and the column name in the second table to match on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_tbl = Table().with_columns(\n",
    "    'Kind', make_array('strawberry', 'chocolate', 'vanilla'),\n",
    "    'Stars', make_array(2.5, 3.5, 4)\n",
    ")\n",
    "\n",
    "ratings_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join cones and ratings\n",
    "cones_tbl.join(\"Flavor\", ratings_tbl, \"Kind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can use the `merge()` function to join two tables together. The first parameter is the name of the second table to join on. The parameters `left_on` and `right_on` specify the columns to use in the left and right tables respectively. There are more parameters such as `how` which specify what kind of join to perform (Inner (Default), Outer, Left, Right). For more information, refer to this [Kaggle Tutorial](https://www.kaggle.com/crawford/python-merge-tutorial/notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new ratings df\n",
    "ratings_df = pd.DataFrame({\"Kind\" : ['strawberry', 'chocolate', 'vanilla'],\n",
    "                           \"Stars\" : [2.5, 3.5, 4]})\n",
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge cones and ratings\n",
    "cones_df.merge(ratings_df, left_on = \"Flavor\", right_on = \"Kind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizing Data <a id='visualizing'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `datascience`, we learned to plot data using histograms, line plots, scatter plots and histograms. The corresponding functions were `hist()`, `plot()`, `scatter()` and `barh()`. Plotting methods in Pandas are nearly identical to `datascience` since both build on the library `matplotlib`\n",
    "\n",
    "In this section we will go through examples of such plots in Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='histograms'></a>**3.1. Histograms**\n",
    "\n",
    "In `datascience`, we used `hist()` to create a histogram. In this example, we will be using data from `baby.csv`. Recall that the baby data set contains data on a random sample of 1,174 mothers and their newborn babies. The column `Birth.Weight` contains the birth weight of the baby, in ounces; `Gestational.Days` is the number of gestational days, that is, the number of days the baby was in the womb. There is also data on maternal age, maternal height, maternal pregnancy weight, and whether or not the mother was a smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datascience_baby = Table.read_table('baby.csv')\n",
    "datascience_baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datascience_baby.hist('Birth Weight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use `hist()` to create histograms, just like `datascience`. Refer to the [documentation](https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.hist.html) for a full list of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby.hist('Birth Weight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='line'></a>**3.2. Line Plots**\n",
    "\n",
    "In `datascience`, we used `plot()` to create a line plot of numerical values. In this example, we will be using census data and plot variables such as Age in a line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line plot in datascience\n",
    "census_tbl = Table.read_table('census.csv').select(['SEX', 'AGE', 'POPESTIMATE2014'])\n",
    "children_tbl = census_tbl.where('SEX', are.equal_to(0)).where('AGE', are.below(19)).drop('SEX')\n",
    "children_tbl.plot('AGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can use `plot.line()` to create line plots. For a full list of parameters, refer to the [documentation](http://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.plot.line.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "census_df = pd.read_csv('census.csv')[[\"SEX\", \"AGE\", \"POPESTIMATE2014\"]]\n",
    "children_df = census_df[(census_df.SEX == 0) & (census_df.AGE < 19)].drop(\"SEX\", axis = 1)\n",
    "children_df.plot.line(x = \"AGE\", y = \"POPESTIMATE2014\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scatter'></a>**3.3. Scatter Plots**\n",
    "\n",
    "In `datascience`, we used `scatter()` to create a scatter plot of two numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "football_tbl = Table.read_table('deflategate.csv')\n",
    "football_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "football_tbl.scatter('Blakeman', 'Prioleau')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use `plot.scatter()` to create a scatter plot. For a full list of parameters, refer to the [documentation](http://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.plot.scatter.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "football_df = pd.read_csv('deflategate.csv')\n",
    "football_df.plot.scatter(x = \"Blakeman\", y = \"Prioleau\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bar'></a>**3.4. Bar Plots**\n",
    "\n",
    "In `datascience`, we used `barh()` to create a horizontal bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.barh(\"letter\", \"points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use `plot.barh()` to create a bar chart. For a full list of parameters, refer to the [documentation](http://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.plot.barh.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_dict.plot.barh(x = 'letter', y = 'points');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "Here is a list of useful Pandas resources.\n",
    "\n",
    "- [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
    "- [Dataquest Pandas Tutorial](https://www.dataquest.io/blog/pandas-python-tutorial/)\n",
    "- [Pandas Cookbook](http://nbviewer.jupyter.org/github/jvns/pandas-cookbook/tree/master/cookbook/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sudden-bosnia",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-preliminary",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-batman",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "When done exporting, download the .zip file by `SHIFT`-clicking on the file name and selecting **Save Link As**. Or, find the .zip file in the left side of the screen and right-click and select **Download**. You'll submit this .zip file for the assignment in Canvas to Gradescope for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-acoustic",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-sailing",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
